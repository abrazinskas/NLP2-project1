07:26:19 [INFO]: Setting up the model, French vocabulary size = 17625, English vocabulary size = 14405, max_jump = 100.
07:26:20 [INFO]: Model has been set up.
07:26:20 [INFO]: Loading parameters from params/ibm1.npy
07:37:11 [INFO]: Iteration  0/5: log_likelihood = -123.0618, val_log_likelihood = -151.2757, validation_AER = 0.3459
07:37:11 [INFO]: Start training model.
08:04:03 [INFO]: Iteration  1/5: log_likelihood = -78.3724, val_log_likelihood = -108.9089, validation_AER = 0.2677
08:33:22 [INFO]: Iteration  2/5: log_likelihood = -74.0838, val_log_likelihood = -104.9519, validation_AER = 0.2752
08:59:35 [INFO]: Iteration  3/5: log_likelihood = -72.9237, val_log_likelihood = -103.7566, validation_AER = 0.2733
09:27:11 [INFO]: Iteration  4/5: log_likelihood = -72.3413, val_log_likelihood = -103.0436, validation_AER = 0.2714
09:54:02 [INFO]: Iteration  5/5: log_likelihood = -71.9653, val_log_likelihood = -102.6107, validation_AER = 0.2677
09:54:02 [INFO]: Done training model.
